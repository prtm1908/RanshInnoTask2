{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"question\", \"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector DB Successfully Created!\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader('data/', glob=\"**/*.pdf\", show_progress=True, loader_cls=PyPDFLoader)\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "vector_store = Chroma.from_documents(texts, embeddings, collection_metadata={\"hnsw:space\": \"cosine\"}, persist_directory=\"stores/insurance_cosine\")\n",
    "\n",
    "load_vector_store = Chroma(persist_directory=\"stores/insurance_cosine\", embedding_function=embeddings)\n",
    "\n",
    "print(\"Vector DB Successfully Created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = load_vector_store.as_retriever(search_kwargs={\"k\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prath\\anaconda3\\envs\\ransh\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"HuggingFaceH4/zephyr-7b-alpha\"\n",
    "\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=repo_id, model_kwargs={\"temperature\": 0.3, \"max_length\": 500}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "\n",
    "def qa_chain():\n",
    "    qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    verbose=True\n",
    "    )\n",
    "    return qa\n",
    "\n",
    "qa = qa_chain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Tommy found a book about school in the attic.\n",
      "0.2968108654022217\n"
     ]
    }
   ],
   "source": [
    "text_query = \"what did tommy find in the attic?\"\n",
    "\n",
    "start_time = time.time()\n",
    "text_response = qa(text_query)\n",
    "print(text_response['result'])\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The text doesn't provide a description of the pages of the book. The conversation only mentions that Tommy found a book in his attic about school, and Margie asks what it's about. Margie then expresses her dislike for school, but there is no further information about the book's pages or content.\n",
      "0.2934699058532715\n"
     ]
    }
   ],
   "source": [
    "text_query = \"Describe the pages of the book\"\n",
    "\n",
    "start_time = time.time()\n",
    "text_response = qa(text_query)\n",
    "print(text_response['result'])\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Margie attended a school with a mechanical teacher.\n",
      "0.29724931716918945\n"
     ]
    }
   ],
   "source": [
    "text_query = \"Which class did Margie had to attend?\"\n",
    "\n",
    "start_time = time.time()\n",
    "text_response = qa(text_query)\n",
    "print(text_response['result'])\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Tommy was mentioned in the context as someone whom Margie addressed a question to. However, no further information about Tommy was provided in the given text to answer the question \"Who was Tommy?\".\n",
      "0.29314661026000977\n"
     ]
    }
   ],
   "source": [
    "text_query = \"Who was tommy?\"\n",
    "\n",
    "start_time = time.time()\n",
    "text_response = qa(text_query)\n",
    "print(text_response['result'])\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Margie is not mentioned in the given context. The passage is describing how schools used to be in the past, and how Isaac Asimov was a renowned science-fiction author. Margie's identity or role in the passage is not clear.\n",
      "0.29085373878479004\n"
     ]
    }
   ],
   "source": [
    "text_query = \"Who was Margie?\"\n",
    "\n",
    "start_time = time.time()\n",
    "text_response = qa(text_query)\n",
    "print(text_response['result'])\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "According to your mother's perspective, teachers were not taught to adjust to fit the mind of each student they teach. They were not taught to teach differently for each student based on their age or individual needs. This is a significant difference from how teachers are taught to teach today.\n",
      "0.2929189205169678\n"
     ]
    }
   ],
   "source": [
    "text_query = \"how were teachers like earlier\"\n",
    "\n",
    "start_time = time.time()\n",
    "text_response = qa(text_query)\n",
    "print(text_response['result'])\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Tommy shows superiority over Margie when he nonchalantly says \"Maybe\" to her offer to read the book with him after school. This implies that he may not want to read with her, or he may have other plans. Margie, on the other hand, seems eager to continue reading the book.\n",
      "0.2911202907562256\n"
     ]
    }
   ],
   "source": [
    "text_query = \"Where does tommy show superiority over margie\"\n",
    "\n",
    "start_time = time.time()\n",
    "text_response = qa(text_query)\n",
    "print(text_response['result'])\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "The inspector had a round little face with a red hue.\n",
      "0.30387258529663086\n"
     ]
    }
   ],
   "source": [
    "text_query = \"give facial characterstics of the inspector\"\n",
    "\n",
    "start_time = time.time()\n",
    "text_response = qa(text_query)\n",
    "print(text_response['result'])\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Margie was disappointed because she had been hoping they would take the mechanical teacher away altogether. She was hoping for a different kind of school, not the one she had.\n",
      "1.829171895980835\n"
     ]
    }
   ],
   "source": [
    "text_query = \"Why was Margie hurt\"\n",
    "\n",
    "start_time = time.time()\n",
    "text_response = qa(text_query)\n",
    "print(text_response['result'])\n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ransh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
